\documentclass[10pt,]{book}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\linespread{1.3}
\ifxetex
  \usepackage{fontspec,xltxtra,xunicode}
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
  \setmainfont{Fanwood Text}
\else
  \ifluatex
    \usepackage{fontspec}
    \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
    \newcommand{\euro}{€}
    \setmainfont{Fanwood Text}
  \else
    \usepackage[utf8]{inputenc}
  \fi
\fi
\usepackage{biblatex}
\bibliography{Thesis}
\usepackage{listings}
\usepackage{fancyvrb}
\usepackage{ctable}
\usepackage{float} % provides the H option for float placement
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex,
              bookmarks=true,
              pdfauthor={},
              pdftitle={},
              colorlinks=true,
              urlcolor=blue,
              linkcolor=blue]{hyperref}
\else
  \usepackage[unicode=true,
              bookmarks=true,
              pdfauthor={},
              pdftitle={},
              colorlinks=true,
              urlcolor=blue,
              linkcolor=blue]{hyperref}
\fi
\hypersetup{breaklinks=true, pdfborder={0 0 0}}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}
\VerbatimFootnotes % allows verbatim text in footnotes

\title{Platform Independent Programs}
\author{Joseph Hallett}
\date{\today}

\widowpenalty=300
\clubpenalty=300
\begin{document}
\maketitle

\tableofcontents
\listoftables
\lstlistoflistings
\chapter{Executive Summary}

This is where the executive summary will go\ldots{} but there is not one
yet.

\chapter{Introduction}

\section{Constructing PIPs}

In 2010 a team of researchers developed a generalised method for
creating Platform Independent Programs (PIPs)\autocite{Cha:2010uh}. A
PIP is a special sort of program which can be run on multiple different
computer architectures without modification. Unlike shell scripts or
programs written for a portable interpreter; a PIP does not require
another program to run or compile it; rather it runs as a native program
on multiple architectures with potentially different behaviour on each.

A more formal definition a PIP is a string of byte-code $b$ such that
for different machines $m_1$ and $m_2$, $b$ is a valid program if:

\[m_1(b) \not = \bot \wedge m_2(b) \not =\bot.\]

To construct a PIP one must analyse the instruction sets of each
architecture and find instructions which compile to identical patterns
of byte-code. The approach taken by the authors in \autocite{Cha:2010uh}
was to find small PIPs with a very specific form: do nothing then jump.
By ensuring each architecture jumped to a different point and that each
architecture did not accidentally run into a region another architecture
jumped into; they could construct PIPs for any arbitrary program by
splitting them up into blocks of instructions specific to each
architecture and connecting them with the small PIPs.

Consider the following example (taken from \autocite{Cha:2010uh}). The
disassembly for the X86 architecture is shown above, and for the MIPS
platform bellow.

\[\underbrace{\overbrace{90}^{\text{NOP}} \overbrace{eb20}^{\text{JMP}}
2a }_{\text{NOP}} \underbrace{90eb203a}_{\text{NOP}}
\underbrace{24770104}_{\text{B}}\]

The string is valid on both platforms and has similar behaviour on both
despite jumping to different locations. In fact this is a valid PIP for
the X86, MIPS and ARM architectures. If we disassemble the pattern with
the Radare2 reverse engineering framework\autocite{radare} we can see
that it disassembles to:

\ctable[caption = Disassembly of an example PIP header from
\autocite{Cha:2010uh}, pos = H, center, botcap]{ll}
{% notes
}
{% rows
\FL
Architecture & Disassembly
\ML
X86 & nop; jmp 0x100000023; sub dl, {[}eax+0x243a20eb{]}; ja
0x10000000c; ???
\\\noalign{\medskip}
ARM & bcs 0x10083ae48; bcc 0x10083ae4c; streq r7, {[}r1{]}, \#-1828
\\\noalign{\medskip}
MIPS & slti zero,s1,-5232; xori zero,s1,0xeb90; b 0x10001dc9c
\LL
}

For the X86 architecture it is a NOP instruction then a jump
instruction. The rest wont be executed (though some of it is valid X86
code) as the unconditional jump will have moved the program counter
along. For the ARM architecture it is starts with two conditional jumps.
The first tests if the processor's carry flag is set, and the next
checks if the carry flag is not set. One of these two instructions will
be executed so one of the two jumps will be taken. For MIPS architecture
the first two instructions write the result of the operation back to
register zero. On the MIPS architecture any writes to register zero are
discarded and the \lstinline!slti! and \lstinline!xori! can not cause
any errors to occur. This means the first two instructions are
equivalent to a \lstinline!NOP! instruction. The third instruction is a
MIPS branch instruction, so the sequence for a MIPS computer is
equivalent to do nothing and jump.

Since for each of the X86, ARM, and MIPS architectures the byte-code is
equivalent to do nothing and jump; the instruction is a valid PIP.

They go on to give a generalised algorithm for constructing these PIPs,
and say that they have a working implementation of it for creating PIPs
for the X86, ARM, and MIPS platforms, as well as the Windows, Mac, and
Linux operating systems.

\section{Aim Of The Project}

For this thesis I have implemented a section of the PIP finding
algorithm: the section for finding the \emph{gadget headers}; the PIPs
that link the specific code sections together. To generate the PIPs a
list of \emph{semantic NOPs}\footnote{A semantic NOP is an instruction
  which has no effect, but which might not necessarily be the \emph{NOP}
  assembly instruction. For example the ARM instruction:
  \lstinline!MOV r4, r4! Causes the contents of register four to be
  moved into register four and as such is equivalent to an actual
  \lstinline!NOP! instruction. Equally the sequence of instructions:
  \lstinline!PUSH r3! \lstinline!POP r3! If equivalent to two
  \lstinline!NOP! instructions when taken as a whole and so is a
  \emph{multi-instruction semantic NOP}.} and potential branch
instructions has been found for each architecture in the original paper
and to extend the work of the original paper I have also analysed a new
platform: XMOS XS1.

Unfortunately there does not seem to be a public database of these
instructions available for \emph{any} architectures. Semantic NOPs have
been used in areas other than creating PIPs, for example malware
classification\autocite{Bilar:2007uu}\autocite{Preda:2007ky}, but there
still appears to be no exhaustive list exists documenting them. Part of
the work required is to create one.

\section{Applications Of PIPs}

PIPs can be used for a variety of applications. One potential
application suggested by Brumley et. al.\autocite{Cha:2010uh} is for
sneaking programs past dynamic execution checkers. Suppose two prisoners
\emph{Alice} \& \emph{Bob}, wish to send a malicious program between
themselves. To send the message they have to send it through a
\emph{Warden} who checks first that there communications don't contain
anything malicious and only delivers the message if its believed to be
harmless.

To sneak the program Alice and Bob use a form of
\emph{keyed-steganography}\footnote{which the
  authors\autocite{Cha:2010uh} call \emph{execution-based
  steganography}.}. The program which they wish to communicate becomes
their \emph{steg-text}, and they construct a \emph{cover-text} by
writing some other program which does not contain anything malicious.
They either pre-arrange a shared secret which is the platform that their
programs should really be run on: this forms the key. With the
cover-text and steg-text created they create their message by generating
them into a PIP where on one platform (X86 say) it appears to run the
innocuous program and on the secret key platform (ARM for the sake of
argument) it runs the program they really wish to communicate. Alice
hands the warden the program and tells him that it is for the innocuous
architecture\footnote{if they were using ELF they would not even need to
  do that---it is part of the header in the file\autocite{mancx:th}.}.
The warden runs the program and sees it is not something he would want
to restrict and delivers it. In fact unless he is aware that it has been
in constructed in this way he may not even check any other architectures
as for most platforms it will appear to be garbage just like any normal
executable.

A more real world example of this is to consider the relationship
between computers (usually using an X86 processor) and modern smart
phones (which often use ARM processors) running \emph{apps}. The
computer often stores backups of the applications used on the
smartphone. Apple's iTunes program, for example, stores all the mobile
applications associated with a user in it is library folder as
zip-compressed archives. Suppose an attacker were to construct a program
which was a lignite application on the ARM platform but when run on X86
behaved as a form of malware. The computer might have some form of
anti-malware software, but unless it knows to scan the mobile
applications as potential X86 viruses rather than the ARM ones they
identify themselves as (and which are not ARM malware) then the
anti-malware program might miss the dangerous code.

Another application is \emph{exfiltration protection}. Exfiltration is
military term meaning the removal of a resource from enemy control. In
the context of PIPs this probably involves taking programs from
protected PCs; kind of like DRM. The idea is that to protect its
software from theft a secret agency could make a modification to an
existing platform (the JVM or another virtual machine would be a good
choice here) and compile their program for this modified platform. They
then create another program for the unmodified platform which does
something else; maybe it phones home, maybe it destroys itself from the
computer it is running on. They create a PIP out of these two programs
and now if the program is stolen and the exfiltrator is not aware of the
PIP nature (or exactly what modifications were made to the architecture)
they cannot execute the program they removed.

Microcode offers another interesting way to use PIPs. Suppose an
attacker manages to compromise a system in such a way that they can
alter the microcode of the processor, such as the recent HP printer
attack amongst others\autocite{Cui:vx}\autocite{Scythale:tk}. Now
suppose that as well as the microcode update they also modify an
existing program, Brumley et. al. suggest \lstinline!ls!, so that on the
compromised system it gives a backdoor or acts maliciously, but on
another (say one which is trying to forensically work out what is wrong
with the printer) it acts normally. Brumley et. al. point
out\autocite{Cha:2010uh} that if this was done by Intel and the PIP was
a preexisting and digitally signed application: it is a particularly
scary prospect. Merely signing the program would be insufficient protect
a user it would not check if the machine it was executing on had been
modified.

PIPs could also be used to create platform independent shell code to
take advantage of buffer overflows on software ported between different
architectures and operating systems. As well as developing PIPs to
create architecture independent programs, Brumley et.
al.\autocite{Cha:2010uh} extended the basic technique to create
operating system programs. For operating system independent programs
they exploited overlaps in calling conventions and interrupts to develop
PIPs which could be valid programs on multiple systems. Brumley et. al.
give an example remote bind-shell shell code for multiple architectures
at the end of their paper \autocite{Cha:2010uh}.

Another application for PIPs is to create actual platform independent
programs. The idea here is to compile a program for multiple
architectures and create a PIP out of them. You would get a program that
behaved the same but ran on multiple architectures. This could be
useful, for example, if you have a network of computers (some Linux X86
based, some ARM based) and you want to run a server hosting all the
programs to share between them you don't have to maintain multiple
versions.

\section{Other Approaches To Program Obfuscation}

The problem is that although PIPs could be used to write architecture
independent programs, there are more elegant solutions available than
relying on the intersection of instruction sets between architectures.
There are a couple of preexisting systems for doing this such as Apple's
\emph{Universal Binary} or the \emph{FatELF}\autocite{Icculus:vl}
format. Another problem is that for some operating systems this just
would not work: Linux normally uses the ELF format\autocite{mancx:th}
which has a flag in the header which specifies exactly what architecture
the binary was compiled for. If it does not match the architecture of
the machine it is being run on, then the loader refuses to run
it\footnote{Of course there is nothing to stop you flipping the flag to
  some other value with \lstinline!elfedit! utility from the GNU
  Binutils.}.

Collberg et. al. \autocite{Collberg:1997vt} describe different methods
for hiding the structure of a program. They give many different
transforms but three are of particular interest: adding dead code,
adding redundant transforms, and outlining\footnote{Outlining is the
  opposite of inlining. For inlining we take a function call and replace
  it with the functions code inserted into the main program verbatim.
  For outlining we take a block of code inside a function and make a
  function call out of it. We might do inlining to skim a couple of jump
  instructions from our program at the expense of a longer program; but
  outlining (especially of sections only run once) just adds to the
  spaghetti nature of the code.} sections of code.

These three are of interest because they describe what a PIP is doing,
namely adding redundant NOPs and transforms which don't alter the state
of the program before jumping to the actual code.

Whilst adding the \lstinline!NOP! instructions is not a particularly
\emph{resilient}\footnote{Resilience is a measure of how easy it is to
  deobfuscate a transform. It is usually measured in terms of the time
  and space the deobfuscator has to run.} transformation (a program
could replace or remove them) they are potent\footnote{Potency measures
  how confusing for a human the transform is. For example self-modifying
  code is a very potent transform, but renaming the jump targets is not.}
especially if they are combined with multi-instruction semantic NOPs
where the state of the program does change only to be reversed later.
The jumps added by the PIPs act to outline blocks of code. If you're
using just one PIP at the start of the program then it is not that
obfuscating but in a situation where you're outlining every single
instruction with a PIP like structure and possibly embedding different
behaviour if it is run on a different architecture (such as Java or
Thumb mode on an ARM chip) this has the potential to be massively
obfuscating.

Interestingly papers, such as
\autocite{Christodorescu:2005vh}\autocite{Christodorescu:2005vf}, even
describe obfuscation techniques where they deobfuscate the addition of
semantic NOPs using a novel (and patented
\autocite{Christodorescu:2009wo}) tool called \emph{Hammock}. Hammock
appears to be interesting because rather than using a catalogue of
pre-known semantic NOPs it finds them by analysing whether sequences of
code have any net effect on the state of the machine. They find it to be
a very slow transform to deobfuscate (implying adding NOPs is a potent
obfuscation technique) but the removal is quick once they have been
found.

Semantic NOPs are another interesting aspect of the PIP problem.
Semantic NOPs are important for PIPs as they give you multiple ways of
doing nothing---so there is a greater chance of finding an overlap
between different architectures but they turn up in other places too.
Many people
\autocite{Christodorescu:2005vh}\autocite{Owens:2011um}\autocite{Bruschi:2007dn}
have suggested using semantic NOPs as an obfuscating technique. Wartell
et. al.\autocite{Wartell:2011ji} suggest using them as part of a
heuristic for differentiating between code and data for disassembled
programs. The GNU Assembler has a short list of efficient, low power
semantic NOP\footnote{A comment above the
  function\autocite{Anonymous:td} notes that most of the instructions
  used as part of the semantic NOP sequences by the assembler are not in
  fact assemblable's with the assembler.} instructions it uses to pad
instruction sequences to cache-lines\autocite{Anonymous:td}.

\section{What Is The Challenge?}

The original PIP paper\autocite{Cha:2010uh} contains an anecdote where
the effort required to create platform independent programs is described
as requiring:

\begin{quote}
``a large, flat space to spread out the architecture reference manuals,
and an ample supply of caffeine. Do not underrate the second part.''

\end{quote}
Brumley et al go on to note that:

\begin{quote}
``even the most caffeinated approaches have only been met with limited
success;''

\end{quote}
For this thesis we are not trying to fully generate platform independent
programs; rather we are just trying to find the headers that enable
them. To do this we need two things: a list of semantic NOP And jump
instructions for each architecture we are interested in, and a method
for combining them to form the headers.

Finding the semantic NOPs and jump instructions in theory is quite easy.
You can go through the architecture manual making notes of the all the
instructions which you're interested in (checking that they don't alter
the state of the processor in any surprising way) before assembling them
to get the bytecode. For some architectures it \emph{is} easy---the
instruction sets are small and everything in the instruction set is
accessible through a standard assembler.

The MIPS architecture\autocite{MIPSTechnologiesInc:2011ta} is a good
example of a platform which it is easy to find semantic NOPs. A short
RISC instruction set, a limited number of status-altering instructions
and a register that discards any value written to it make it and ideal
platform for writing semantic NOPs. Several million single instruction
semantic NOPs can be found with minimal effort. The Intel X86
architecture\autocite{IntelCorporation:1997ta} is completely different
however. There are a large number of instructions here including
multiple forms of the same instructions which the assembler is free to
pick between. All arithmetic instructions alter status flags. Worse
still there are some assembly instructions that can not be assembled by
the GNU tool chain\autocite{Anonymous:td}. It is considerably harder to
find semantic NOPs for the X86 architecture.

Once we know the form of the instructions we want to assemble we need to
compile and disassemble them to get the bytecode, and store them in a
database. Once we have them in an indexable format we need to search for
the patterns that overlap and find all the PIP headers. There are
significant problems associated with finding these PIP headers. For
platforms like ARM\autocite{Seal:2000vd} and
MIPS\autocite{MIPSTechnologiesInc:2011ta} instructions are all compiled
to be of fixed length (four bytes). In this case we could find short
PIPs by comparing the lists of NOP instructions for one architecture and
jump instructions for the other. We could extend them to arbitrary
lengths by finding the NOPs which do nothing on both architectures and
padding to the length required.

In practice however this approach doesn't work. Variable length
instruction sets, such as X86\footnote{For example the instruction
  \lstinline!NOP! compiles to \lstinline![0x90]!, but the
  \lstinline!movsldup xmm0,xmm1! instruction becomes
  \lstinline![0xF3, 0x0F, 0x12, 0xC1]!.}, mean you need to combine
instructions together to get them to the length you require. If there
were only a few identifiable patterns of semantic NOPs and jump
instructions then this approach might be feasible but the numbers become
huge. For example on many architectures there is an unconditional jump
instruction. If this instruction takes a thirty-two bit address to jump
to then there are $2^{32}$, over four billion, possible forms of this
instruction to check. And this is just one instruction. On X86 it even
has more than one compiled form. Conditional jumps exasperate the
problem further. For a conditional jump you need two (or more!) jump
instructions, so that means $2^{64}$ possible variants to check which is
huge.

The MIPs architecture demonstrates well nether issue. With the MIPS
architecture you have a register called zero which discards any value
written to it. This offers great opportunities for finding semantic
NOPs, but it also presents further problems with the size of patterns
you can find. The \lstinline!ADDI! instruction, for example, is used to
add a sixteen bit number to a register and then write back to another
one. MIPS registers are represented in an instruction using five bits
and it doesn't matter which of them we use (so long as we write back to
zero). A sixteen bit immediate, plus a five bit register means
twenty-one bits we don't care about in this instruction, and over two
million permutations of this single instruction. Even if we use tricks
to reduce the problem size we still have problems. Even restricting the
search to a small subset of the possible patterns the amount of memory
required to store them is large---hundreds of gigabytes. If we want to
be able to detect when there are PIPs in a file we need to be able to
search these files; again computationally expensive.

Detecting PIPs is another difficult problem. There is currently no data
as to how often these patterns occur in regular files. Since the
instruction sequences used in PIPs are valid for multiple architectures
a PIP instruction sequences could turn up in a program without being
part of some malicious behaviour. Data for how often PIPs turn up in
normal code is needed before any statistical model for detecting them
can be made.

This data does not currently exist.

\chapter{Technical Basis}

To construct PIPs three tasks need to be accomplished: find the
instructions that can be used to form semantic NOPs; chain them together
with jump instructions to create the potential PIPs for a given
architecture; finally compare the potential PIPs for each architecture
to see if any of them exist in both architectures. These are the PIPs we
are interested in.

\section{Computer Architecture Background}

To construct PIPs instructions must be assembled and the bytecode
examined. Processors fetch instructions in a binary format, a string of
1s and 0s, which we call bytecode. Each architecture has its own
specific form of bytecode; that is to say if \lstinline!1010100101!
means add two registers on one architecture then there are no guarantees
that this pattern means the same thing on another---or even that the
other has registers to add together.

Every instruction a processor wishes to offer has to be mapped to a
sequence of bytecode\footnote{This is true in general but slightly
  oversimplified. The X86 and ARM instruction sets both feature special
  instructions which can change how sequential pieces of bytecode are
  decoded. For example the ARM architecture\autocite{Seal:2000vd} can
  switch to decoding the THUMB or JVM instruction sets by using the
  \lstinline!BX! instruction (which has the bytecode of
  \lstinline!e12fff10!). X86\autocite{IntelCorporation:1997ta} offers
  similar a similar mechanism for turning on or off feature sets which
  can alter how instructions are decoded.}. Some architectures, such as
ARM\autocite{Seal:2000vd} MIPS\autocite{MIPSTechnologiesInc:2011ta} and
X86\autocite{IntelCorporation:1997ta}, are register based (they expect
data to be used in calculations to be stored in special pieces of memory
called registers) and the instructions take arguments saying exactly
which registers to use. Others, such as the
JVM\autocite{Lindholm:2012wy}, are stack based (they expect arguments to
operations to be stored in a data structure called a stack where the top
one or two items are the operands to most instructions.

Different architectures offer different sorts of instructions. The X86
achitecture offers a large number of instructions which can do many
different things such as AES encryption and arithmetic{[}@refX86{]}. The
ARM architecture\autocite{Seal:2000vd}, however, is much smaller---it
doesn't have a division instruction. The XS1
architecture\autocite{May:ua} has several instructions for concurrency
and communicating over ports which are not present on other
architectures. To make matters more complex the length of instructions
also varies on an architecture by architecture basis: MIPS and ARM
instructions are always four bytes long but the X86 and JVM instruction
sets use a variable length instruction size.

When a processor wishes to execute a program (formed of bytecode) it
\emph{fetches} the instruction (or instructions if the processor is
superscalar) to be run, \emph{decodes} what the instruction is to do
before \emph{executing} it and \emph{writing back} the result. For this
project we are targeting the decode stage. We are trying to find
bytecode that decodes to legitimate instructions for multiple
processors, and then using this bytecode to make arbitrary programs.

\section{Semantic NOPs}

Formally a semantic NOP is an instruction that has no net effect on the
state of the processor other than moving the program counter to the next
instruction. A semantic NOP is functionally equivalent to the
\lstinline!NOP! opcode (which often is a synonym for a low-power
semantic NOP). Specifically if the outcome of the machine executing an
instruction is functionally equivalent to the machine executing the
\lstinline!NOP! instruction, independent of the state of the
machine\footnote{e.g.~the instruction would always behave as a
  \lstinline!NOP! instruction even if a conditional execution flag was
  set differently.}, then it is a semantic NOP.

For example on the ARM architecture\autocite{Seal:2000vd} the
\lstinline!NOP! instruction is assembled into the bytecode
\lstinline!e1a00000!. The instruction \lstinline!mov r0, r0! is also
assembled to \lstinline!e1a00000!. Because they have the same bytecode
we can see that these two instructions are actually one and the same.
The designers of the architecture chose to replace the \lstinline!NOP!
instruction with a functionally equivalent one in the bytecode format.
This is done (amongst other reasons) to compress the instruction set.
Here the \lstinline!mov r0, r0! instruction is the \lstinline!NOP!
instruction as well as being functionally equivalent to it, but the
designers of the architecture could have chosen differently. The
instruction \lstinline!mov r1, r1! is functionally equivalent to the
\lstinline!NOP! command as well but the bytecode to represent it is
\lstinline!e1a01001! which is different to the \lstinline!NOP!
instruction. This means that \lstinline!mov r1, r1! is a semantic
NOP---it has the same behaviour as the \lstinline!NOP! instruction and a
different bytecode.

The instruction \lstinline!movgt pc, r2! however would not be a semantic
NOP instruction. Here the instruction will behave as a NOP instruction
unless the greater than flags are set when it will move the contents of
register two into the program counter. This isn't a semantic NOP because
though it will behave like a \lstinline!NOP! instruction some of the
time it might not do. If a programmer had added this instruction knowing
that the greater than flags would never be set when this instruction was
executed then it would be very similar to a semantic NOP but more often
called \emph{dead code}\autocite{Collberg:1997vt}.

There is another sort of semantic NOP we have used: a multi-instruction
semantic NOP. This is a sequence of instructions that may alter the
state of the machine, but will reverse any change they make by the end
of the sequence; they are a redundant transform. For example the
sequence \lstinline!ADD r0,r0,#1!, \lstinline!SUB r0,r0,#1! is a
redundant transform as any change to the state of the machine
(specifically register zero) is undone by the second
instruction\footnote{On the X86
  architecture\autocite{IntelCorporation:1997ta}, however, this wouldn't
  be a semantic NOP as arithmetic operations alter status flags as well
  as the registers they operate on{[}@refxasmnet:vu{]}.}. We call
sequences like this semantic NOPs as well though more care must be taken
when using these as if the machine were to handle an interrupt whilst
executing one the state of the machine might be altered unpredictably.

Searching for the semantic NOPs is book work. You take the architecture
manual and search through it; making a notes of the mnemonic, arguments
and whether any exceptions could be raised or flags overwritten. For
simple instruction sets (like ARM or MIPS) this can be done in a couple
of hours; but for complex instruction sets this can be an arduous
process\footnote{Resources such as the \emph{X86 Opcode and Instruction
  Reference} {[}@refX86{]} are invaluable for discovering what each
  instruction actually does in a clear format.}.

Once you have found the instructions you want to use for a semantic NOP
you have to deal with the problem of scale: there are a lot of them.
Here you have two concerns: for a list of semantic NOPs you want clarity
of instruction and to be easily able to identify assembled and
disassembled forms. An easy way to do this is to store the bytecode with
the assembly instructions used to generate it. A problem with this
approach, however, is that the lists can become large. An alternative to
this is to introduce \emph{don't care} bytes into the compiled forms.

Consider this example: a simple semantic NOP for the MIPS architecture
is \lstinline!addiu zero,t0,0!. It has the (big-endian) compiled form of
\lstinline!25000000!. Another semantic NOP is
\lstinline!addiu zero,t0,1! which compiles to \lstinline!25000001!. But
for this instruction so long as you write back to the \lstinline!zero!
register the instruction is always a semantic NOP. Looking at the
architecture manual\autocite{MIPSTechnologiesInc:2011ta} there are no
exceptions that can be raised by it so its safe to use as a semantic
NOP. The manual lists describes the instruction
\lstinline!addiu rt,rs,immediate! as:

\[GPR[rt] \gets GPR[rs] + immediate\]
\[\mathtt{\overbrace{0010\;01}^\text{opcode}
\overbrace{\cdot\cdot\;\cdot\cdot\cdot}^\text{rs}
\overbrace{0\;0000}^\text{rt}\; \overbrace{\cdot\cdot\cdot\cdot\;
\cdot\cdot\cdot\cdot\; \cdot\cdot\cdot\cdot\;
\cdot\cdot\cdot\cdot}^\text{immediate}}\]

If we were going to enumerate every possible combination of operands for
this single instruction we would get around two-million\footnote{There
  are twenty-one free bits in the instruction, so there are $2^{21}$
  possible enumerations; which is 2,097,152 in real numbers.} possible
semantic NOPs just from this single instruction. Whilst for a database
this is desirable to accurately describe every possible semantic NOP,
for generating PIPs this becomes a problem. To generate the PIPs we need
to combine them with other semantic NOPs and jump instructions. By
working with the representation with \emph{don't cares}\footnote{Actually
  you end up using the hexadecimal notation because it works better with
  disassembler tools. For this instruction ends up being stored as
  $\mathtt{2[4567][2468ace]0\cdot\cdot\cdot\cdot}$ which has
  twenty-eight possible enumerations not including don't cares. This
  turns out to give a good balance between wanting a short list of
  instructions and a readable format.} we can dramatically cut the
number of permutations of instructions. This is important when the
numbers of semantic NOPs becomes huge, and the instructions are shorter
(i.e.~with X86) as the running time to find them can become excessive.

\section{Generating PIPs}

Once we have the list of semantic NOPs we then need a list of possible
jump instructions. We generate this list the same way we find the
semantic NOPs: enumerating the possible operations and then generalising
by introducing \emph{don't care} symbols\footnote{A \emph{don't care}
  symbol represents a bit or byte of the instruction set whose value we
  don't care about. For example the X86 short jump instruction could be
  represented in byte-code as \lstinline!eb..! where \lstinline!.! is
  the don't care symbol. We care that it is a jump instruction, which
  the \lstinline!eb! encodes; but we might not care where it jumps to so
  we can represent the destination with \emph{don't cares}.}. Again
multibyte jumps are possible on some architectures (such as ARM) by
exploiting conditional execution.

Once you have the two sets---semantic NOPs and jumps---for the
architecture you can proceed as follows: pick a length of the PIP
pattern you want to find, add a jump instruction on the end of the PIP.
Subtract the length of the jump instruction from the pattern length and
then for every possible semantic NOP add it to the start of the PIP. If
it has not made the PIP too long, output it as a possible PIP before
trying to add another semantic NOP onto the pattern. Finally pad any
output PIPs to the required length with don't cares if it is not long
enough. Pseudo code for this process is given below in a python-esque
language.

\begin{lstlisting}[language=python ,
caption=Algorithm used to generate PIPs]
def generate_possible_nop_jump_patterns(length, nop_list, jump_list):
    for jump in jump_list:
        pattern = [jump]
        for PIP in pad_with_nops(pattern, length, nop_list):
            PIP = pad_with_dont_cares(PIP, length)
            print PIP

def pad_with_nops(pattern, length, nop_list):
    if length(pattern) < length:
        yield pattern
        for nop in nop_list:
            pattern = nop : pattern
            for each PIP in pad_with_nops(pattern, length, nop_list):
                yield PIP           
\end{lstlisting}
Once we have done this for multiple architectures we can try and find
PIPs which are valid for two or more architectures. To do this we find
the PIPs in each architecture which have equivalent forms and produce a
new PIP from them which forces some of the don't-cares to actualy values
if one of the PIPs demands it.

\begin{lstlisting}[language=haskell ,
caption=Method used for removing \emph{don't-cares} from potential PIP headers]
-- Equality with don't cares
(~=~) :: Nibble -> Nibble -> Bool
'.' ~=~ _   = True
x   ~=~ '.' = True
x   ~=~ y   = x == y

-- Do two PIPs match?
matches :: PIP -> PIP -> Bool
x `matches` y = and $ zipWith (~=~) x y

-- Resolve two PIPs to remove don't cares if required
resolve :: PIP -> PIP -> PIP
resolve = zipWith resolve'
  where
    resolve' x y
     | x == y    = x
     | x == '.'  = y
     | y == '.'  = x
     | otherwise = error "Resolving unresolvable characters"

{- Given two sets of PIPs, produce a third containing 
   the valid PIPs for both architectures -}
findPIPs :: [PIP] -> [PIP] -> [PIP]
findPIPs PIPs1 PIPs2 = 
    [ resolve x y
    | x <- PIPs1                            
    , y <- PIPs2                                      
    , x `matches` y
    ]
\end{lstlisting}
These PIPs are the ones we particularly interested in. We can repeat the
process again to find PIPs for multiple architectures if we like by
using the generated set of PIPs as one of the input sets.

\section{An Alternative Approach}

The approach taken here to find the PIPs is similar to the one taken by
Cha et al\autocite{Cha:2010uh} to find their gadget headers (though they
do not give a specific algorithm for this section). However alternative
approaches are also possible. A good area to provide an alternative
method for is the semantic nop section.

As described earlier; adding dead or garbage code is an established
obfuscation technique, and it is in current use in several metamorphic
codes such as Evol, ZMist, Regswap and
MetaPHOR\autocite{Borello:2008vx}. Identifying dead code sequences is a
technique already used by several anti virus tools as part of their
toolchains. These can be leveraged to finding semantic NOPs by getting
them to output the offending sequences.\footnote{Actually this does not
  work quite as described. A really simple and often used trick to
  implement dead code insertion is to introduce unreachable code that
  looks as if it could be reached (i.e.~by placing a conditional jump
  that is always taken just before it). This unreachable code might not
  necessarily have no net effect on the program execution but because it
  will never be run it does not matter anyway. From the point of view of
  a metamorphic virus this is an attractive technique because of the
  greater freedom of content inside the dead-code segment; and so many
  more variants of the malware. For PIPs this technique is not useful
  (or rather implementing the always-taken-jump before the dead code is
  what we are trying to do rather than the writing dead-code). Coverage
  tools such as \emph{gcov} can be used to find unreachable code such as
  this.\autocite{Administrator:ul} For finding semantic NOPs more
  advanced tricks need to be used.}

One approach to identify these semantic NOP based sequences is to use
signatures\footnote{Have a big list of \emph{signatures}; see if any
  match the bit of code you're looking at.}, but this requires the
semantic NOPs to have been previously identified. An alternative scheme,
used by the SAFE tool\autocite{Christodorescu:2006vz}, is to find the
semantic NOPs is to try and analyze sections of code and see if there
would be any net change in the state of a machine if they were to run
them. This is similar to simulation but has the added challenge of being
able to tell if \emph{any} input would cause a change of state rather
than just the single input that is simulated.

To do this you need to keep track of all the variables and what
transformations are applied to them over the course of the program.
Calculations like this become unfeasible quickly and there are no
guarantees that they will find any semantic NOP regions. The other
problem with this strategy for finding semantic NOPs is that the regions
of code can be very large. For the purposes of this project it is
preferable that any patterns found be short; so actually just using the
architecture manual and hand picking, as it were, one or two instruction
sequences to form the semantic NOPs is preferable. Also for the
sequences of only one or two instructions it is quite easy to find every
possible semantic NOP pattern.

Because of the increased complexity and running time of this method I
did it by hand instead. This had the advantage of being simple, easy and
ensured I did not miss any details, such as side effects or missing
instructions. For finding the PIPs I believe this was the better method
in this case.

\section{Malware Detection Methods}

Given that we can use PIPs to create programs with steganography it
would be helpful to be able to distinguish PIP from non-PIP. Malware
detection gives a set of methods to accomplish this.

Using the detection notion defined in \autocite{Preda:2007ky} we define
a malware detector as the following. Given the set of every possible
program $\mathbb{P}$ there is a subset $\mathbb{M}$ that have malicious
behaviour. \[\mathbb{M\subset P}\] For some of the programs in
$\mathbb{M}$ we have a signature $s$ which is formed in some way from
the program. A detector $D$ is a function that given a $p\in\mathbb{P}$,
and a signature $s$ says true if the signature was formed from that
program and false otherwise. The

We can evaluate the detector and a set of signatures by seeing how well
it can distinguish malware from non-malware. The false-negative rate is
the percentage of all the malware which the detector fails to report as
being malware. The false-positive rate is the percentage of all
non-malware detector incorrectly reports as being malware. Depending on
the where the malware detector is being used the false positive and
negative rate can be tweaked to requirements by altering the set of
signatures and how they are generated. The approach of detecting malware
by its appearance is popular; however in general detecting whether a
program is malware by appearance is an undecidable problem
\autocite{Cohen:1987wt}\autocite{Shyamasundar:2010tl}.

There are several different approaches to generating malware signatures.
One approach is to use a section of the malware itself to form a
signature. To do this they give a regular expression that specifies a
sequence of byte or instruction sequences that are considered malicious.
If the malicious sequences of code are seen in a program the malware
detector reports it as malware. To avoid these techniques new forms of
\emph{polymorphic} and \emph{metamorphic} malware have been developed
which use self modifying code and encryption to hide these signatures
from signature based detectors\autocite{Christodorescu:2005vf}.

Other approaches to getting and evading signatures have been developed.
One approach to avoiding signature matching is to randomize the order of
some
expressions\autocite{Borello:2008vx}\autocite{Christodorescu:2005vf}. To
counter these obfuscations approaches which use control flow patterns as
signatures have been developed\autocite{Bonfante:2007th}. The idea is
that whilst some sub-expressions may be rearranged the algorithms
themselves cannot be so dramatically changed. These approaches have been
relatively successful at detecting polymorphic malware
\autocite{Kang:2011bs}\autocite{Bruschi:vb}. Another approach is to use
model checking to try and identify sections of code that copy the
instruction sequences to different locations or which use suspicious
parts of the Windows API\autocite{Kinder:2005hu}. To counter these
improved protections more techniques have been developed. One approach
to detecting malware is to simulate it and see if it does anything
suspicious. To counter this malware authors have taken to putting in
NP-HARD problems into their code so that any simulator also has to solve
a problem such as 3-SAT\autocite{Moser:2007cd}---this slows detection.

Various toolchains have been developed to aid detecting malware. The
Binary Analysis Platform\autocite{Brumley:wn} is one such platform which
works by reduction to an intermediary language. It offers support for as
well as malware detection; automatic exploit
generation\autocite{Avgerinos:vo}, signature generation, and formal
verification. Other platforms, such as
CodeSurfer\autocite{Balakrishnan:2005tx}, are built on top of IDA
Pro\autocite{HexRays:up}. CodeSurfer works with IDA to provide more
representations of a program; the idea is that these
extra-representations allow an analyst to reason about what a piece of
malware does.

\section{Tool-Chains Used}

\chapter{Components}

\begin{itemize}
\item
  I used the GNU compiler toolchains for ARM, MIPS, X86 to assemble
  lists of semantic NOPs.
\item
  I used the XMOS toolchain to assemble lists of semantic NOPs for the
  XS1 architecture.
\item
  I used the Jasmine assembler to explore writing semantic NOPs for the
  JVM.
\item
  I used the Radare 2 framework to write semantic NOPs and jumps with
  don't care bytes for ARM, MIPS and X86 as well as to verify the PIPs
  at the end. I also used its JVM dissasembler and assembler to explore
  the JVM for creating PIPs.
\item
  I used Ruby and Haskell to write various tools to create the PIPs.
\item
  I refered to the architecture manuals for ARM,
  MIPS\autocite{MIPSTechnologiesInc:2011ta}, X86 and XS1 extensively
  throughout the project but also made use of the ARM and Thumb
  Instruction Set Quick Reference Card\autocite{Limited:vc} and X86
  Opcode reference{[}@refX86{]}.
\end{itemize}
\chapter{Execution}

\section{Semantic NOPs}

\ctable[caption = Semantic NOP sequences identified per architecture.,
pos = H, center, botcap]{ll}
{% notes
}
{% rows
\FL
Architecture & Semantic NOPs Identified
\ML
ARM & 187,879
\\\noalign{\medskip}
MIPS & 18,958,336
\\\noalign{\medskip}
X86 & 1,266
\\\noalign{\medskip}
XS1 & 792
\LL
}

Around nineteen million semantic NOP sequences for the ARM, MIPS, X86
and XS1 architectures were identified and stored in a database of the
form:

\[\text{\sc Semantic-NOPs}\left( 
\text{\underline{architecture}}, 
\text{instruction prefix}, 
\text{instruction suffix},
\text{\underline{bytecode prefix}},
\text{\underline{bytecode suffix}}
\right)\]

By using prefix and suffixes we can separate certain multi-instruction
semantic NOPs from the rest. Some multi-instruction semantic NOPs can be
written with more semantic NOPs within them and by using this prefix and
suffix form we can distinguish the bit which needs to go first from the
bit which must come at the end.

For example consider these entries from the database:

\ctable[pos = H, center, botcap]{lllll}
{% notes
}
{% rows
\FL
Architecture & Instruction Prefix & Instruction Suffix & Bytecode
Prefix & Bytecode Suffix
\ML
X86 & PUSH \%rax & POP \%rax & 50 & 58
\\\noalign{\medskip}
X86 & NOP &  & 90 & 
\LL
}

The bytecode \lstinline!90! is a semantic NOP---the \lstinline!nop!
instruction. Equally the sequence \lstinline!push %rax; pop %rax! is a
semantic NOP sequence with bytecode \lstinline!5058!. For the
\lstinline!push!-\lstinline!pull! sequence we can place any code in
between the \lstinline!push! and the \lstinline!pull!. If that sequence
is a semantic NOP too then the sequence as a whole is a semantic NOP
also. So \lstinline!509058! is a semantic NOP; as is
\lstinline!50909058!; or ever \lstinline!5050905858!.

Looking at the numbers found in Table 5.1 the MIPS architecture is by
far the easiest to find semantic NOPs for. The MIPS register zero (which
discards all writes to it) enables any instruction to be easily
converted to a semantic NOP just by writing back to register zero.
Furthermore there are four different instructions in the MIPS
architecture which take a sixteen bit immediate value as an operand and
can be used without triggering an
exception\autocite{MIPSTechnologiesInc:2011ta}: \lstinline!addiu!,
\lstinline!andi!, \lstinline!ori! and \lstinline!slti!. These can all be
used to generate semantic NOPs; but more importantly give us sixteen
free bits for when we are trying to find the PIPs.

ARM is the next easiest (though there are a hundredth of what can be
found for MIPS). The ARM7 architecture supports conditional execution
which helps for finding semantic NOPs. Conditional execution is
implemented by having four bits encode a conditional flag and one bit
used to indicate that the system flags should be
updated\autocite{Seal:2000vd}. If the flag is matched then the command
is executed else the command becomes a NOP. We have less registers than
MIPS and while we have three instructions which can be used with
immediate values (\lstinline!add!, \lstinline!sub! and \lstinline!eor!)
they only use an eight-bit value (as well as input to a barrel shifter).

X86 has significantly less semantic NOPs than ARM or MIPS. One reason
for this is a lack of instructions that don't alter the state of the
processor in some way: all the arithmetic instructions update flags
inside the processor. There are no instructions we can use with an
immediate value to write a semantic NOP. The XS1 architecture has a
similar number of semantic NOPS to X86 for similar reasons. There are
less registers than X86 and only a limited number of instructions that
take an immediate value that can be used for writing semantic NOPs.

\subsection{The JVM}

The JVM is an interesting architecture but very different from all the
others I looked at. The JVM is a virtual stack based
architecture\autocite{Lindholm:2012wy}. Stack based architectures don't
use registers like the X86 ARM or MIPS architectures, but rather expect
most of their instructions operands to be on a stack in memory. Some JVM
instructions do take arguments passed as part of the bytecode
instruction; such as the \lstinline!goto! and \lstinline!goto_w!
instructions which take the two or four byte address to go to as an
argument. Most do not however and most JVM instructions are only one
byte long. Within functions the JVM imposes some strict rules about the
size of the stack and constants available. If the size of the stack
exceeds the limit imposed then an exception is triggered.

This leads to some problems with trying to find semantic NOPs for the
JVM. Most JVM NOPs that can be found are multi-instruction. There is a
\lstinline!nop! instruction (\lstinline!00!), but in general to write a
semantic NOP for the JVM you need to push and pull values on and off the
stack. There are JVM instructions for rearranging the stack which can be
used to create semantic NOPs---the \lstinline!swap! instruction
(\lstinline!5f!) could be issued twice but even this only works if you
know the type of the top two elements of the stack and can be sure they
are the same type. Unless you know something of the program you're
adding these kinds of semantic NOPs too you can very easily end up
triggering an exception from misuse of the stack.

Another problem with the JVM is from the complexity from chaining
together the instructions. If you ignore the problems associated with
limited stack space and assume an unlimited amount of stack then you
still have to cope with the problems of enumerating. Specifically you
need to find a sequence of instructions such that the stack is unchanged
overall; but since most of the instructions take from the stack and add
back to it you can use most of them so long as you pop (perhaps using
the \lstinline!pop! (\lstinline!57!) or \lstinline!pop_2!
(\lstinline!58!) instructions) any additional values back off at the end
and make sure there are enough useless values on the stack initially so
as not to alter any pre-existing ones. Any dead-code program will work,
which unfortunately means that there are a lot of them and they can be
very long. An interesting side point here is that there are quite a lot
of tools out there to detect Java dead code sequences: such as
DCD\autocite{Vermat:wk} and UCD\autocite{Spieler:uz}. The JDK hotspot
compiler can optimize dead code sequences away\autocite{Goetz:ua}. It
would be an interesting problem to see how rare dead code sequences are
in regular compiled code (i.e.~programs from Java code rather than
handwritten JVM bytecode). Dead code elimination is a common
optimization, and I would suspect the answer is not often.

\section{PIPs}

\ctable[caption = Four byte PIPs found between architectures.,
pos = H, center, botcap]{lllllc}
{% notes
}
{% rows
\FL
\emph{Architecture} & ARM LE & ARM BE & MIPS LE & MIPS BE & X86
\ML
ARM LE &  & $6.6\times10^{4}$ & 0 & $2.6\times10^{5}$ & 0
\\\noalign{\medskip}
ARM
BE & $6.6\times10^{4}$ &  & $2.6\times10^{5}$ & 0 & $7.0\times10^{4}$
\\\noalign{\medskip}
MIPS LE & 0 & $2.6\times10^{5}$ &  & $1.0\times10^{6}$ & 0
\\\noalign{\medskip}
MIPS
BE & $2.6\times10^{5}$ & 0 & $1.0\times10^{6}$ &  & $2.8\times10^{5}$
\\\noalign{\medskip}
X86 & 0 & $7.0\times10^{4}$ & 0 & $2.8\times10^{5}$ & 
\LL
}

\ctable[caption = Eight byte PIPs found between architectures. On top of
these results $2.0\times10^{10}$ were found which were valid for the ARM
LE MIPS BE and X86 architectures., pos = H, center, botcap]{lllllc}
{% notes
}
{% rows
\FL
\emph{Architecture} & ARM LE & ARM BE & MIPS LE & MIPS BE & X86
\ML
ARM
LE &  & $3.1\times10^{14}$ & $2.8\times10^{14}$ & $1.2\times10^{15}$ & $1.1\times10^{12}$
\\\noalign{\medskip}
ARM
BE & $3.1\times10^{14}$ &  & $1.2\times10^{15}$ & $2.8\times10^{14}$ & $6.2\times10^{14}$
\\\noalign{\medskip}
MIPS
LE & $2.8\times10^{14}$ & $1.2\times10^{15}$ &  & $4.5\times10^{15}$ & $4.2\times10^6$
\\\noalign{\medskip}
MIPS
BE & $1.2\times10^{15}$ & $2.8\times10^{14}$ & $4.5\times10^{15}$ &  & $2.4\times10^{15}$
\\\noalign{\medskip}
X86 & $1.1\times10^{12}$ & $6.2\times10^{14}$ & $4.2\times10^{6}$ & $2.4\times10^{15}$ & 
\LL
}

Tables 5.2 and 5.3 show the number of PIPs found of length four and
eight bytes respectively. For four byte headers we found a similar
number to Brumley et. al. \autocite{Cha:2010uh} for the ARM and X86
architectures (tens of thousands), however we found significantly more
for the MIPS and any other architecture than Brumley (hundreds for
Brumley et. al. versus tens to hundreds of thousands for us). Brumley
et. al. don't give numbers for how many eight byte headers they can find
however their numbers for twelve byte headers are around a thousand to
ten-thousand times bigger than the number found for eight byte headers.
This seems fairly reasonable considering the number of possible
different bytecode sequences for a twelve byte sequence is $2^{96}$
rather than only $2^{64}$ for an eight byte one.

\subsection{Why So Few For MIPS?}

I am unsure why Brumley et. al. found so few four byte PIP headers for
the MIPS architecture. For the twelve byte sequences the number of PIP
headers they found between the MIPS and any other architecture is
significant but for four byte sequences their number found is very low.
For example they only found six PIP headers between the MIPS little
endian and big endian architectures. This suggests they didn't use the
MIPS jump instruction to find any of their sequences.

The MIPs jump instruction has the following
format\autocite{MIPSTechnologiesInc:2011ta}:
\[\mathtt{000010\overbrace{\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot}^\text{address}}\]

Its easy to find a four byte PIP header for the little and big endian
variants of the MIPS architecture by using this instruction. If we
switch the endianess of the instruction and then remove all the $\cdot$s
that overlap with a fixed bit we find that a jump instruction for both
MIPS endianesses has the form in binary of:
\[\mathtt{000010\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot\cdot000010\cdot\cdot}\]
Where $\cdot$ indicates either a 1 or a 0. If we convert this sequence
to hexadecimal we get the set of four byte PIP headers for different
MIPS endianess variants that I identified.

\[\mathtt{08....08, 08....09, 08....0a, 08....0b, 09....08, 09....09, 09....0a, 09....0b} \brace \mathtt{ 0a....08, 0a....09, 0a....0a, 0a....0b, 0b....08, 0b....09, 0b....0a, 0b....0b}\]

\section{Detecting PIPs}

\ctable[caption = Number of times eight byte PIP headers occur in ARM
programs and the percentage of the total program which they occupy. All
of the programs listed \emph{apart from Mother 3 and Random} are taken
from iPhone applications for Apple's iOS operating system. \emph{Mother
3} is a program for Nintendo's GameBoy Advance. Random is a long string
of random bytes., pos = H, center, botcap]{lllll}
{% notes
}
{% rows
\FL
Program & ARM BE (\%) & MIPS BE (\%) & MIPS LE (\%) & X86 (\%)
\ML
DrawSomethingFree & 203 (0.0\%) & 834 (0.1\%) & 215 (0.0\%) & 1 (0.0\%)
\\\noalign{\medskip}
Dropbox & 79 (0.0\%) & 375 (0.1\%) & 89 (0.0\%) & 1 (0.0\%)
\\\noalign{\medskip}
Mother 3 & 3426 (0.1\%) & 3181 (0.1\%) & 2227 (0.1\%) & 2 (0.0\%)
\\\noalign{\medskip}
Pages & 696 (0.0\%) & 2659 (0.1\%) & 651 (0.0\%) & 7 (0.0\%)
\\\noalign{\medskip}
SwordAndSworcery & 136 (0.0\%) & 545 (0.1\%) & 129 (0.0\%) & 0
\\\noalign{\medskip}
Vim & 32 (0.0\%) & 160 (0.1\%) & 33 (0.0\%) & 0
\\\noalign{\medskip}
\emph{Random} & 25 (0.0\%) & 94 (0.1\%) & 17 (0.0\%) & 0
\LL
}

\ctable[caption = Number of times eight byte PIP headers occur in X86
programs and the percentage of the total program that they occupy. The
programs \emph{cat, echo and ls} and small UNIX utilities. \emph{Hello}
is the hello-world program written in C. \emph{Clang} is a C compiler;
\emph{nasm} is an assembler and \emph{pandoc} is a Haskell based
markdown compiler. \emph{Linux-2.6} is the Linux kernel and
\emph{mach\_kernel} is a version of the Mach kernel by Carnegie Mellon
University found in Apple's MacOS Lion., pos = H, center, botcap]{lllll}
{% notes
}
{% rows
\FL
Program & ARM BE (\%) & ARM LE (\%) & MIPS BE (\%) & MIPS LE (\%)
\ML
hello & 0 & 0 & 0 & 0
\\\noalign{\medskip}
cat & 0 & 0 & 0 & 0
\\\noalign{\medskip}
clang & 223 (0.0\%) & 0 & 6299 (0.2\%) & 0
\\\noalign{\medskip}
echo & 0 & 0 & 4 (0.1\%) & 0
\\\noalign{\medskip}
linux-2.6 & 264 (0.1\%) & 0 & 918 (0.2\%) & 0
\\\noalign{\medskip}
ls & 2 (0.0\%) & 0 & 19 (0.2\%) & 0
\\\noalign{\medskip}
mach\_kernel & 237 (0.0\%) & 0 & 5266 (0.3\%) & 0
\\\noalign{\medskip}
nasm & 7 (0.0\%) & 0 & 72 (0.2\%) & 0
\\\noalign{\medskip}
pandoc & 582 (0.1\%) & 0 & 2147 (0.1\%) & 0
\\\noalign{\medskip}
\emph{Random} & 39 (0.0\%) & 1 (0.0\%) & 205 (0.2\%) & 0
\LL
}

To test the steganographic properties of PIPs I looked at how often they
occur in various programs for the ARM and X86 architectures. I chose to
look at X86 and ARM as they are two of the most commonly found
architectures today. A processor with the X86 instruction set
architecture is inside most consumer PCs and servers. The ARM
architecture\footnote{Specifically the ARM 7 32-bit architecture known
  as AArch32 not the new shiny 64-bit one.}, however, is found
everywhere. It is the dominant processor inside mobile phones with both
Google's Android and Apple's iOS platforms running on this architecture.
ARM chips are often found in embedded systems and have even been found
in massively parallel supercomputers\autocite{Khan:2008uv}.

For the ARM architecture I focussed on \emph{app-like} programs. I
looked at a variety of apps from games to text editors as well as a
sequence of random bytes and a Gameboy advance game. The Gameboy game is
interesting as it also contains sound and graphics files built into it
that the iOS applications do not. The results are shown in Table 5.4.
The results seem to show that PIP headers very rarely turn up in ARM
code; less than 0.1\% typically. Some PIP headers turn up for the ARM
little endian and MIPS architectures, but next to none ever turn up for
X86 PIP headers in ARM little endian programs. It would be surprising if
more that ten turned up in any program. Another interesting point is
that PIP headers don't appear to turn up in programs more often than
they do in a random sequence of code. For X86 we see similar results
(Table 5.5). I looked at a range of program from very simple C programs
and system utilities, to compilers and two operating system kernels.
Again we see that NOPs turn up very rarely in bytecode,

In Brumley et. al.'s paper\autocite{Cha:2010uh} they suggest that whole
platform independent programs could be created by splitting the program
into several \emph{gadgets} each with a PIP header and a block of code
to be executed for each platform the program author wishes to target.
Brumley et. al. go on to suggest that a program could be split up into
gadgets one instruction in length, however since each each gadget would
feature a PIP header this would likely destroy any steganographic
properties the author want in their program. Because PIP headers are
rare; a program with execution based steganography could be
distinguished from a plain text by counting the number of PIP headers
that could be found and deciding whether that number is statistically
significant. When an author is trying to hide X86 behaviour this is a
much bigger problem as the number of PIP headers that could be expected
to turn up naturally in a program is very low.

\subsection{Detecting With Static Analysis}

If including several PIP headers and splitting the program into lots of
small sections is going to remove steganographic properties what about
using fewer gadgets and having longer section of platform specific code?
The problem with this approach is that it becomes very susceptible to
static analysis. Suppose we were to take a program for ARM and were to
disassemble as if it were a program for X86. There are likely to be a
fair number of valid instructions in it for X86 just from the fact that
a large amount of X86 bytecode is also valid ARM bytecode because
designers of architectures like to make instruction sets dense for
encode efficiency; but if we were to start seeing sequences that look
like X86 calling conventions then we might immediately become suspicious
that there is some steganographic execution behaviour hidden.

As an example consider this PIP taken from \autocite{Cha:2010uh}:

\ctable[caption = A PIP containing a \emph{Hello World} program for ARM
MIPS and X86., pos = H, center, botcap]{ll}
{% notes
}
{% rows
\FL
Hexadecimal & Characters
\ML
\texttt{7f454c46 01010100 00000000 00000000} & \texttt{\frenchspacing .ELF............}
\\\noalign{\medskip}
\texttt{02000300 01000000 54800408 34000000} & \texttt{\frenchspacing ........T...4...}
\\\noalign{\medskip}
\texttt{00000000 00000000 34002000 01000000} & \texttt{\frenchspacing ........4. .....}
\\\noalign{\medskip}
\texttt{00000000 01000000 00000000 00800408} & \texttt{\frenchspacing ................}
\\\noalign{\medskip}
\texttt{00800408 f4000000 f4000000 05000000} & \texttt{\frenchspacing ................}
\\\noalign{\medskip}
\texttt{00100000 90eb3e20 1700002a 1600003a} & \texttt{\frenchspacing ......> ...*...:}
\\\noalign{\medskip}
\texttt{07000010 00000424 2128e003 0c000624} & \texttt{\frenchspacing .......\$!(.....\$}
\\\noalign{\medskip}
\texttt{a40f0224 0c000000 a10f0224 0c000000} & \texttt{\frenchspacing ...\$.......\$....}
\\\noalign{\medskip}
\texttt{f8ff1104 00000000 48656c6c 6f20776f} & \texttt{\frenchspacing ........Hello wo}
\\\noalign{\medskip}
\texttt{726c640a 90909090 eb1731db 438b0c24} & \texttt{\frenchspacing rld.......1.C..\$}
\\\noalign{\medskip}
\texttt{ba0c0000 00b80400 0000cd80 31c040cd} & \texttt{\frenchspacing ............1.\@.}
\\\noalign{\medskip}
\texttt{80e8e4ff ffff4865 6c6c6f20 576f726c} & \texttt{\frenchspacing ......Hello Worl}
\\\noalign{\medskip}
\texttt{640a9090 0100a0e3 18108fe2 0c20a0e3} & \texttt{\frenchspacing d............ ..}
\\\noalign{\medskip}
\texttt{0470a0e3 000000ef 0000a0e3 0170a0e3} & \texttt{\frenchspacing .p...........p..}
\\\noalign{\medskip}
\texttt{000000ef 0000a0e1 48656c6c 6f20576f} & \texttt{\frenchspacing ........Hello Wo}
\\\noalign{\medskip}
\texttt{726c640a} & \textbackslash{}texttt\{\frenchspacing rld. \$\}
\LL
}

If we ignore that the program has the text \emph{Hello world} three
times in the bytecode the program might not be immediately suspicious.
The program only uses one platform independent section to split the
code, so it isn't particularly suspicious by counting PIP headers. If we
disassemble the code, however, it starts to become far more suspicious.
In Listing 5.1 a section of the program disassembled for X86
architecture. Two system calls (the \lstinline!int 0x80!) are clearly
made\autocite{Kerrisk:vo}. Before each system call arguments are loaded
such that the first is a write operation, and the second is an exit.
This program clearly has some X86 behaviour.

\begin{lstlisting}[basicstyle=\tt, ,
caption=A disassembled section of the PIP in Table 5.6 for the X86 architecture.]
write:
        xor ebx, ebx
        inc ebx
        mov ecx, [esp]
        mov edx, 0xc
        mov eax, 0x4
        int 0x80
exit:
        xor eax, eax
        inc eax
        int 0x80
\end{lstlisting}
If we disassembler the program in Table 5.6 as an ARM program (as shown
in Listing 5.2) however we can quickly find an equivalent section of
code. Again this is all valid ARM code and it obviously does a write
system call followed by an exit. It's in the PIP too so the PIP must
have ARM behavior as well as X86; this program is probably a PIP and we
have discovered this just by inspecting the disassembly---a form of
static analysis.

\begin{lstlisting}[basicstyle=\tt, ,
caption=A disassembled section of the PIP in Table 5.6 this time for the ARM architecture.]
write:
        mov r0, #1 ; 0x1
        add r1, pc, #24 ; 0x18
        mov r2, #12 ; 0xc
        mov r7, #4 ; 0x4
        svc 0x00000000
exit:
        mov r0, #0 ; 0x0
        mov r7, #1 ; 0x1
        svc 0x00000000
\end{lstlisting}
If we try again using a MIPS disassembler we get the code in Listing
5.3. Again its pretty obvious what is going on and it didn't take long
to find even by eye. This PIP is probably valid on the MIPS platform as
well as X86 and ARM, and we've done this through simple static analysis.
None of these sections of code are long---around nine instructions---and
yet they give a strong indication that the program has PIP behaviour. It
would be an interesting extension to look at creating a static analyser
to detect how much valid code for different architectures there is in a
program and whether any of it seems to form a valid program snippet.

\begin{lstlisting}[basicstyle=\tt, ,
caption=A disassembled section of the PIP in Table 5.6 for the MIPS architecture.]
write:
        li a0,0
        move a1,ra
        li a2,12
        li v0,4004
        syscall
exit:
        li v0,4001
        syscall
\end{lstlisting}
\subsection{Hiding PIP Code}

Given that excessive use of PIP headers appears to make it obvious when
a program is a PIP and that having long sequences of platform specific
code give the game away as well; is there any way to use PIPs without
destroying the steganographic properties? Several techniques have been
developed for creating analysis resistant
malware\autocite{Bethencourt:2008ug} which could equally be applied to
resisting PIP detection. Using signatures is relatively primitive
technique for detecting malware\autocite{Zhang:2007jy} and several
techniques have been developed which can evade it as well as improve
upon it.

One approach is to use encryption. The program code is stored inside the
program as data but at run time the program decrypts it back to
executable code\autocite{Royal:2006ug}. This resists static analysis
because the section of code we would want to analyze can't be read
without decryption. Unless we can recover the key and know how to
decrypt the program we might not be able to spot the PIP behaviour. Of
course to do the decryption on multiple platforms we're either going to
need a PIP malware extractor but if this can be written using less PIP
headers than the full program then it might be a way forward.

Developing methods for detecting encrypted or packed malware is a
current research topic and there have been several tools developed for
detecting this\autocite{Chouchane:2006cf}\autocite{Zhang:2007jy}. These
could be applied to detecting packed PIP code as well.

Metamorphic malware\autocite{Sikorski:2011ua} takes a similar approach.
It again uses self-modifying code to alter a program so that it can
evade signature based detection. An approach would be to have a program
that alters instructions to create the gadget headers in Brumley's
paper\autocite{Cha:2010uh} dynamically based on runtime information.
This suffers from similar problems to the encryption approach of needing
a PIP modifier and there are several available techniques for detecting
it \autocite{Han:2011iu}\autocite{Ali:2011do}.

Another approach might be to issue a microcode
update\autocite{Smotherman:2010wr}. The idea here is that rather than
try and decrypt part of the program so that it is valid we alter how the
processor decodes the program so that the previously invalid buffer is
now a valid program; perhaps even for multiple architectures. Issuing
microcode updates involves modifying the BIOS and is typically used by
processor designers to patch bugs in the processor. The technique is
known to be difficult to utilize\autocite{Skoudis:2004to} but is also
very difficult to detect. It would be extremely interesting to look
further at using microcode updates to create PIPs as there appears to be
less available research on the topic.

\section{Writing Programs with PIPs}

To demonstrate PIPs I created a shell code (shown in Listing 5.4) for
the MIPS and X86 architectures using existing platform specific shell
codes by Richard Imrigan\autocite{Imrigan:vg} and
TheWorm\autocite{TheWorm:vp}. The shell code uses a single PIP header
which would also allow this PIP to be valid for the ARM architecture if
it were extended further.

\begin{lstlisting}[basicstyle=\tt, , mathescape=true, ,
caption=An example of a shell code PIP for X86 and MIPS which attempts to spawn a shell and elevate permissions.  Shellcode for each architecture was taken from \autocite{Imrigan:vg}\autocite{TheWorm:vp}.]
eb020008 00000000 6a175831 dbcd80b0 80b02ecd 806a0b58 9952682f 2f736868
2f62696e 89e35253 89e1cd80 00000000 00000000 00000000 00000000 00000000
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
                         $\mathrm{\normalsize\vdots \text{\ \textsf{89 lines ommited}\ } \vdots}$ 
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
00000000 00000000 2806ffff 3c0f2f2f 35ef6269 afaffff4 3c0e6e2f 35ce7368
afaefff8 afa0fffc 27a4fff4 2805ffff 24030fab 0101010c 
\end{lstlisting}
Clearly the shell code is far from ideal. A decompilation of the PIP
header can be seen in Table 5.7, but an immediately obvious flaw is that
the PIP header used has a nil byte in it. Even discarding the long
sequence of nil bytes in the middle of the program (which could be
filled with any value as it is not executed) the shell code is long.
This really isn't a particularly effective bit of shell code. The
earlier shell code in Table 5.6 was much shorter; so why is this one so
much longer?

\ctable[caption = Decompilation of the PIP header used in Listing 5.4,
pos = H, center, botcap]{ll}
{% notes
}
{% rows
\FL
Description & Value
\ML
Bytecode & \lstinline!eb020008 00000000!
\\\noalign{\medskip}
X86
Disassembly & \lstinline!jmp 0x100000004; add [eax], cl add [eax], al; add [eax], al;!
\\\noalign{\medskip}
MIPS Disassembly & \lstinline!j 0x100000bac; nop;!
\\\noalign{\medskip}
ARM Disassembly (unsused) & \lstinline!bl 0x100080028; andeq r0, r0, r0!
\LL
}

\subsection{Liveness and PIPs}

\chapter{Conclusion}

\appendix

\printbibliography[title=Bibliography]

\end{document}
